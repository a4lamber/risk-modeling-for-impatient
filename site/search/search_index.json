{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Risk Modeling for the impatient","text":"<p>This website is designed for those who </p> <ul> <li>wants to break into risk modeling in a bank institution but lack of domain knowledge</li> <li>has STEM background (basic math is needed)</li> </ul> <p></p>"},{"location":"#what-youll-learn","title":"What You'll Learn","text":"<ul> <li>Foundations of Risk Modeling: Understand key concepts, technical jargon and some domain specific knowledge</li> <li>Risk Modeling: Learning about PD, LGD and EAD model</li> <li>Advanced Topics: Explore more complex areas of risk modeling, including stress testing, scenario analysis, and financial forecasting.</li> </ul>"},{"location":"#join-our-community","title":"Join Our Community","text":"<p>Be part of a community of like-minded professionals who are expanding their expertise into risk modeling. Share your progress, ask questions, and network with peers and experts.</p> <p>[To be continuted, probably gonna be a slack and discord channel]</p>"},{"location":"risk_model/101/","title":"Risk Model 101","text":""},{"location":"risk_model/101/#overview","title":"Overview","text":"<p>Risk modeling is the bread and butter for bank. At the end of the day, risk model delivers <code>scorecard</code> looks like this, </p> <p></p> <p>There are primarily two types of scorecards used in banking:</p> <ul> <li> <p><code>Application Scorecard</code>: Used to evaluate new loan applicants. The model considers factors such as credit history, income, employment status, and debt-to-income ratio to determine whether bank will prove your loan or not. Boolean result</p> </li> <li> <p><code>Behavioral Scorecard</code>: Used for existing customers, typically to assess the likelihood of default based on past account behavior. It considers factors like payment history, account balances, recent transactions, and usage patterns etc. It's a online-model since data will kick in at run time (probably not real time but monthly batched prob)</p> </li> </ul> <p>ML in banking</p> <p>Due to regulation, risk modeling uses non-convoluted and very explainable/interpretable model like logarithmic regression for starter.</p> <p>The application score card will base on your age, income, credit history etc to assessing risk to see if your score is over the cutoff, binary classification problem.</p>"},{"location":"risk_model/101/#key-components-of-a-scorecard-model","title":"Key Components of a Scorecard Model","text":"<p>The scorecard uses variables or features (e.g., age, income, credit history) relevant to assessing credit risk.</p> <ul> <li><code>Weightings</code>: Each variable is assigned a weight based on its predictive power. The more influential a variable, the higher its weight.</li> <li><code>Score</code>: The model produces a credit score, often ranging from 300 to 850 in consumer credit scoring systems like FICO. Higher scores indicate lower credit risk.</li> <li><code>Cutoff Score</code>: Banks set a cutoff score, above which applicants are approved and below which they may be rejected or subjected to additional scrutiny.</li> </ul>"},{"location":"risk_model/101/#how-banks-use-scorecard-models","title":"How Banks Use Scorecard Models","text":"<ul> <li><code>Credit Approval</code>: Banks use scorecards to automatically decide whether to approve or reject loan applications. This helps streamline the approval process.</li> <li><code>Risk-Based Pricing</code>: The score determines the interest rate offered to a borrower. Higher-risk customers may be charged higher rates to offset the risk of default.</li> <li><code>Regulatory Compliance</code>: Scorecards support compliance with regulatory requirements by providing objective, data-driven criteria for lending decisions.</li> <li><code>Portfolio Management</code>: Behavioral scorecards help banks monitor existing customers and proactively manage credit limits, upgrade or downgrade products, and initiate early intervention if a customer\u2019s risk profile changes.</li> <li><code>Fraud Detection</code>: Scorecard models can include features related to transaction behavior and account activity to detect potential fraud.</li> </ul>"},{"location":"risk_model/101/#building-a-scorecard-model","title":"Building a Scorecard Model","text":"<p>Building a scorecard typically involves the following steps:</p> <ul> <li><code>Data Collection</code>: Historical data on customer profiles and loan performance.</li> <li><code>Feature Engineering</code>: Selecting and transforming features that are predictive of risk.</li> <li><code>Model Development</code>: Using statistical techniques like logistic regression, decision trees, or machine learning to create a predictive model.</li> <li><code>Model Validation</code>: Testing the model on out-of-sample data to ensure accuracy. Deployment and Monitoring: Implementing the model in production and monitoring its performance over time to adjust for changes in customer behavior or economic conditions. Scorecard models are central to credit risk management, allowing banks to make informed lending decisions and maintain a balanced portfolio while minimizing the risk of defaults.</li> </ul>"},{"location":"risk_model/101/#summary","title":"Summary","text":"<p>In this section, we talked about how risk model used in a bank's setting and why it's needed. We shall dig in.</p>"},{"location":"risk_model/101/#financial-jargons","title":"Financial Jargons","text":"<p>In this section, we will learn</p> <ul> <li>what is credit risk?</li> <li>Why risk modeling</li> </ul> <p>Those are the metrics we gonna center around and learn about </p>"},{"location":"risk_model/101/#what-is-credit-risk","title":"What is credit risk?","text":"<p>Imagine a relationship between Creditor(lender) and debtor (Borrower). Debtor typically borrow something (money, home loan, credit card) with interest rate for incentive of the lender. The lender has the profit of interest with the risk of borrower never pays back</p> <ul> <li><code>collection cost</code>: the cost associated with how creditor get back the money</li> <li><code>default</code>: an event that borrower has no money to pay. </li> </ul>"},{"location":"risk_model/101/#why-risk-modeling","title":"Why risk modeling","text":"<p>If bank institution can have a handy tool that determines whether the borrower is trust-worthy or not, that will be awesome since it's directly related with their profit, take RBC for example, their revenue breakdown for the last couple of years are (source)</p> - 2019 2020 2021 2022 2023 Personal and Commercial Banking 17.86B 17.73B 18.35B 20.14B 22.12B Wealth Management 12.14B 12.22B 13.30B 14.85B 17.54B Capital Markets 8.29B 9.88B 10.19B 9.12B 11.05B Insurance 5.71B 5.36B 5.60B 3.51B 5.67B Investor and Treasury Services 2.35B 2.21B 2.16B 2.22B - Corporate Support - - 100M - - <p>The personal and commercial banking loan takes a huge chunk of business and that's the incentive behind developing these model. </p> <p>On the other hand, this industry is highly regulated. Regulator publish Basel III accord to basically enforce bank institution to have enough money to survive if there are too many defaults. Bank has to implement it and so the risk modeling has two primary stakeholders:</p> <ul> <li><code>stakeholder: regulator</code>: deliver model and its result to regulator. Be more careful with your results and interoperability</li> <li><code>scorecard</code>: teams supporting scorecard for loan application etc</li> </ul>"},{"location":"risk_model/101/#el-pd-lgd-and-ead","title":"EL, PD, LGD and EAD","text":"<p>We gonna learn four technical jargons that modeller cares and they are illustrated in the equation below</p> <p>$$ \\begin{equation} EL = PD \\times LGD \\times EAD \\end{equation} $$ where \\(EL\\) is Expected Loss, \\(PD\\) is Probability Default, \\(LGD\\) is Loss Given Default and \\(EAD\\) is Exposure At Default</p> <p>EL is a type of loss where the total loss consists of EL, UL and potential loss</p> <ul> <li>EL (expected loss): affected by the credit risk. </li> <li>UL (unexpected loss): result of adverse economic circumstances like financial crisis.</li> <li>Potential losses: unlikely to happen and hard to measure.</li> </ul> <p>Only EL is able to be modelled and predicted as illustrated in the image below and that's the primary concern</p> <p></p> <p>Our goal is to measure EL or expected credit loss. EL has three composition</p> item description \u5927\u767d\u8bdd probability of default The borrowers inability to repay their debt in full or on time \u501f\u503a\u8005\u591a\u5c11\u6982\u7387\u8fd8\u4e0d\u4e0a\u94b1 loss given default (<code>LGD</code>) The proportion of the total exposure that cannot be recoved by the lender once a default occurred. LGD = outstanding loan balance - Recovery Amount \u4e00\u65e6\u8fd8\u4e0d\u4e0a\u94b1(default happens),\u591a\u5c11\u8d44\u4ea7\u94f6\u884c\u62ff\u4e0d\u56de\u6765, \u6bd4\u5982\u94f6\u884c\u501f\u4e8610\u4e07\u7684loan, default\u4e86\uff0c\u62ff\u56de\u67654\u4e07\uff0c\u4e8f\u4e866\u4e07\u3002LGD\u5c31\u662f6/10=60%, \u4e5f\u5c31\u662floss/loan ratio. Exposure at default (<code>EAD</code>) The total value that a leander is exposed to when a borrower defaults \u5047\u8bbeborrower defaults,\u4e8f\u591a\u5c11? <p>Question</p> <p>If some1 wants to buy a 0.5 million house, loan to value is 80%. Last year, 1 out of 5 people who defaults (Assuming PD=25%). loaner paid 40,000. what if happen, assuming bank can immediately auction the hour and get back 342,000. What's the EL?</p> <p>equation of EL is,</p> \\[ \\begin{align} EL = PD\\times LGD \\times EAD \\end{align} \\] <p>Since the loaner already paid 40,000, so the EAD is  $$ \\begin{equation} EAD = 400,000 - 40,000 = 36,000 \\end{equation} $$</p> <p>Assuming default and bank auctioned the house for another 342,000, bank will lose 36,000 - 342,000 = 18,000. We can use the loss to calculate LGD</p> \\[ \\begin{align} LGD &amp;= \\frac{18000}{360000} = 5\\% \\\\ PD &amp;= 25\\% \\times 5\\% \\times 360000 = 4500 \\end{align} \\] <p>Then the EL is self-explanatory</p>"},{"location":"risk_model/101/#capital-adequacy-regulations-and-the-basel-guideline","title":"Capital adequacy, regulations and the Basel Guideline","text":"<p>In this section we will cover,</p> <ul> <li>Capital Adequacy Ratio</li> <li>Base II accords</li> </ul> <p>To avoid financial crisis like the one happened in 2008, a series of regulation has been proposed and bank have to adhere to like the capial requirement.</p> <p>capital requirement: AKA capital adequacy or regulatory capital. It's the minimum amount of money the bank should have to recover default loss.</p> <p>$$ \\begin{equation} CAR = \\frac{Capital}{\\text{Risk-weighted assets}} &gt; \\% \\end{equation} $$ where CAR is capital adequacy ratio </p> <p>Warning</p> <p>Besides Basel III, you will also hear IFRS 9. They have different guidelines for - classifying assets  - PD model for example. - time measurement</p> <p>\\</p> <p>Basel II Accord</p> <ul> <li>how much capital banks need to have</li> <li>how capital is defined</li> <li>how capital is compared against risk-weighed assets</li> </ul> <p>An overview of the Basel Accord is shown in the flowchart below</p> <pre><code>flowchart TD\nbasel(\"Basel II Accord\")\na(\"Minimum Capital Requirements\")\nb(\"Supervisory Review\")\nc(\"Market Discipline\")\na1(\"credit risk\")\na2(\"operational risk\")\na3(\"market risk\")\nbasel --&gt; a &amp; b &amp; c\na --&gt; a1 &amp; a2 &amp; a3\na11(\"SA\")\na12(\"IRB\")\na1 --&gt; a11 &amp; a12\na121(\"F-IRB\")\na122(\"A_IRB\")\na12 --&gt; a121 &amp; a122</code></pre> <p>|-|-|description| |-|-|-|-| |SA|standardized approach|not flexible since all external| |IRB|internal rating based|-| |F-IRB|Foundation IRB|-| |A-IRB|Advanced IRB|-|</p>"},{"location":"risk_model/101/#basel-ii","title":"Basel II","text":"- SA F-IRB A-IRB PD Externally Provided Internally estimated Internally estimate LGD Externally Provided Externally Provided Internally estimate EAD Externally Provided Externally Provided Internally estimate <p>External Provider in USA</p> <p>In USA, Popular External provider includes FICO, S&amp;P Global, Moody's and Fitch Rating.</p> <p>\u57fa\u672c\u4e0a\u94f6\u884c\u4e1a\u52a1\u7684\u903b\u8f91\u662f, always starts from SA, then to F-IRB and A-IRB. </p> <p>\u7531\u4e8eSA\u90fd\u662fexternal data source, regulator\u7ed9\u7684\u90fd\u662f\u4fdd\u5b88\u4f30\u8ba1\uff0c\u6240\u4ee5\u7ed9\u7684\u8981\u6c42RWA\u5f88\u5927\u3002\u6240\u4ee5\u5355\u4f4dcapital\u80fd\u501f\u51fa\u53bb\u7684loan\u5c31\u66f4\u5c0f,\u4e5f\u5c31\u662f\u66f4\u5c11\u6536\u76ca\u3002\u94f6\u884c\u4e3a\u4e86\u501f\u51fa\u53bb\u66f4\u591a\u7684\u8d37\u6b3e\uff0c\u9700\u8981\u7528\u522b\u7684regulator-approved approach\u6765\u66f4\u7cbe\u786ecalculate\u6fc0\u8fdb\u7684RWA, \u53ef\u4ee5\u53c8\u5408\u89c4\u53c8\u80fd\u501f\u51fa\u53bb\u66f4\u591a\u7684\u94b1.</p> <p>rating system</p> <p>Credit score\u5bf9\u4e8e\u516c\u53f8/\u653f\u5e9c\u4e00\u822c\u662f\u7ed9A+,B++\u7684rating, \u5bf9individual\u662fnumeric score.</p>"},{"location":"risk_model/pd/","title":"PD Model","text":"<p>PD (probability of default) model is a binary classification problem. Let's assume we use logistic regression to solve this problem.</p>"},{"location":"risk_model/pd/#mathematical-formulation","title":"Mathematical Formulation","text":"<p>In this section, we will go over the full derivation of PD model</p> <p>First, let's recall linear combination and rewrite it in matrix notation</p> \\[ \\begin{align} z &amp;= \\beta_0x_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n \\end{align} \\] <p>We can rewrite linear combination in matrix form, $$ \\begin{align} z &amp;= \\omega^{T}x_i + b \\end{align} $$ where \\(\\omega = {\\beta_0 + \\beta_1 + \\beta_2 + ... + \\beta_n}\\), \\(\\omega^{T}\\) is the transpose of it, \\(b\\) is the constant term</p> <p>Recall the sigmoid function (logistic function),</p> \\[ \\begin{align} y(z) = \\frac{e^{z}}{1+e^{z}} \\end{align} \\] <p>As illustrated in the image below</p> <p></p> <p>We can rewrite equation 3 into,</p> \\[ \\begin{align} y &amp;= \\frac{e^{z}}{1+e^{z}}\\\\ 1- y &amp;= \\frac{1+e^{z}}{1 + e^{z}} - \\frac{e^{z}}{1+e^{z}}\\\\ 1- y &amp;= \\frac{1}{1+e^{z}} \\end{align} \\] <p>We can rearrange \\(y\\) and \\(1-y\\) into its ratio as,</p> \\[ \\begin{align} \\frac{y}{1-y} = \\frac{\\frac{e^{z}}{1+e^{z}}}{\\frac{1}{1+e^{z}}} = e^{z} \\end{align} \\] <p>We take logarithmic on both side, $$ \\begin{align} \\ln \\frac{y}{1-y} = \\ln e^{z} = z \\end{align} $$</p> <p>We substitute linear combination equ 2 into equ 8, we get</p> <p>$$ \\begin{align} \\ln \\frac{y}{1-y} = \\omega^{T}x + b \\ \\ln \\frac{P(y = 1 | x)}{P(y=0|x)} = \\beta_0x_0 + \\beta_1x_1 + ... + \\beta_nx_n \\end{align} $$ Where \\(P(y=1|x)\\) is the probability of an event occur given x.</p>"},{"location":"risk_model/woe_iv/","title":"WOE and IV","text":"<p>In this section, we will talk about WoE (weight of evidence) and IV(information value) in the context of logistic regression for risk modeling.</p>"},{"location":"risk_model/woe_iv/#introduction","title":"Introduction","text":"<p>WoE, in the context of risk modelling does three things, </p> <ul> <li><code>binning of feature</code> such that it's monotonic to reduce statistical noise by removing non-linearity. And feature's interoperability (at the cost of losing prediction power)</li> <li><code>Substitute Continuous Variable</code>: Use age for example, convert age --&gt; age group and then calculate their respective \\(WoE_i\\) for each age group. Use \\(WoE_i\\) instead of age-group in the logistic model, labelled as age.</li> <li><code>Substitute Categorical</code>:</li> </ul> <p>Tip</p> <p><code>WoE</code> and <code>IV</code> is useful for feature binning but limited only in binary classification, usually logistic regression. If modeller wish to try out different model like SVM, you have to use other binning strategy. It is due to SVM can capture non-linear relationship between predictor and target value. If you only use WoE, which require monotonicity, you will end up losing the non-linearity feature which serves no good for non-linear model like SVM.</p>"},{"location":"risk_model/woe_iv/#woe-and-iv-math-formulation","title":"WOE and IV Math Formulation","text":"<p>Let's assume our target value of 1 as good and 0 as bad, </p> <p>\\(WoE_i\\) (weight of evidence) is defined as</p> \\[ \\begin{align} WoE_i &amp;= ln\\left(\\frac{\\textbf{num of good in class i}}{\\textbf{num of total good}}\\right) - ln\\left(\\frac{\\textbf{num of bad in class i}}{\\textbf{num of total bad}}\\right)\\\\ &amp;= ln\\left(\\frac{\\%\\textbf{ of good in class i}}{\\%\\textbf{ of bad in class i}}\\right)\\\\ \\end{align} \\] <p>where \\(WoE_i\\) is the weight of evidence for \\(i\\) th bin, % of good in class is also called distribution of good in some texts.</p> <p>As for \\(IV_i\\), it's dependent on </p> <p>$$ \\begin{align} IV_i &amp;= WoE_i \\times \\left(\\textbf{\\% of good in class i} - \\textbf{\\% of bad in class i}\\right)\\ \\text{IV} &amp;= \\sum_{i=1}^{n} IV_i \\end{align} $$ We typically talk about information value as \\(\\sum_{i=1}^{n} IV_i\\) </p>"},{"location":"risk_model/woe_iv/#woe-intuition","title":"WoE Intuition","text":"<p>WoE is useful for binning, let's say continuous variable like age. Binning or bucketing is often used to convert</p> <p>For example, </p> Age Group Good Bad WoE IV 18-35 2000 400 -0.75 0.23 36-55 3402 201 0.47 0.08 56-70 1900 92 0.67 0.09 Total 7302 693 - 0.4 <p>If we draw out diagram, due to it's logarithmic nature</p> <p></p> <p>In feature engineering, some questions naturally arises, such as </p> <ul> <li>weight of evidence (WOE) values maintain a monotonic relationship with the 1/0 variable (loan default or not default for example.)</li> <li>each bin is reasonably sized and large enough to be representative of population segments,</li> <li>Optimize IV value in the process of binning (iterative process)</li> </ul>"},{"location":"risk_model/woe_iv/#woe-derivation","title":"WoE Derivation","text":"<p>It's bugging me where the jargon \\(WoE\\) is from. It turns out nothing but a ratio that obtainable by substituting linear model to sigmoid function will yield WoE, (add equations here)</p> <p>Recall sigmoid and its derivative</p> \\[ \\begin{align} y = \\frac{1}{1 + e^{-z}} \\\\ y^{'} = y\\times \\left(1-y\\right) \\end{align} \\] <p>For sigmoid we can have,</p> \\[ \\begin{align} y &amp;= \\frac{1}{1 + e^{-z}} = \\frac{e^{z}}{1 + e^{z}}\\\\ 1 - y &amp;= \\frac{1 + e^{z}}{1 + e^{z}} - \\frac{e^{z}}{1 + e^{z}} = \\frac{1}{1 + e^{z}}\\\\ \\frac{y}{1-y} &amp;= e^{z} \\end{align} \\] <p>Then we write the linear regression in matrix form</p> \\[ \\begin{equation} z = \\omega^{T}x + b \\end{equation} \\] <p>We substitute the linear regression to \\(\\frac{1}{1-y} = e^{z}\\) and take log on both sides</p> \\[ \\begin{align} \\frac{y}{1-y} &amp;= e^{\\omega^{T}x + b} \\\\ \\ln \\frac{y}{1-y} &amp;= \\omega^{T}x + b \\\\ \\end{align} \\] <p>where \\(y\\) being good, \\(1-y\\) being bad, \\(\\omega\\) and \\(b\\) are the parameters we need to optimize for our objective function.</p> <p>We can then write the above formation in another form</p> \\[ \\begin{align} \\ln \\frac{P\\left(y=1 \\mid x \\right)}{P\\left(y=0 \\mid x \\right)} &amp;= \\omega^{T}x + b \\\\ \\end{align} \\] <p>Note</p> <p>\\(P\\left(y=1 \\mid x \\right)\\), the probability of an event happening. \\(P\\left(y=0 \\mid x \\right)\\), is the probablity of an event not happening. If we roll a coin and wants head</p> \\[ \\begin{align} \\ln \\frac{P\\left(y=1 \\mid x \\right)}{P\\left(y=0 \\mid x \\right)} &amp;= \\frac{0.5}{0.5} \\end{align} \\] <p>Similarly, if we wish to roll a dice of 6, </p> \\[ \\begin{align} \\ln \\frac{P\\left(y=1 \\mid x \\right)}{P\\left(y=0 \\mid x \\right)} &amp;= \\frac{\\frac{1}{6}}{\\frac{5}{6}} \\end{align} \\] <p>Does it look familiar? the \\(\\ln \\frac{P\\left(y=1 \\mid x \\right)}{P\\left(y=0 \\mid x \\right)}\\) is a ratio of percentage of good over percentage of bad, which is equal to \\(WoE_i\\). Weight of evidence is just a made-up name that shows this relationship. Then the next of the logistic regression is to determine \\(\\omega\\) and \\(b\\), which can be solved by</p> <ul> <li>cross entropy as loss function and gradient descent</li> <li>maximum likelihood method</li> </ul>"},{"location":"risk_model/woe_iv/#discussion-on-monotonicity","title":"Discussion on monotonicity","text":"<p>An example of coarse binning and find binning is shown here, </p> <p></p> <p>WoE and sigmoid</p> <p>Recall sigmoid is smooth, monotonic, and differentiable</p> <ul> <li><code>smooth</code> and <code>differentiability</code>: ensure optimization technique like gradient descent or Adam optimization to work</li> <li><code>monotonicity</code>: WoE, like sigmoid, also needs to be monotonic. That's the core of linear model.</li> </ul>"},{"location":"risk_model/woe_iv/#iv-intuition","title":"IV Intuition","text":"<p>\\(\\sum IV_i\\) has been used to measure the predicting power of predictor, generally under the guideline of following </p> Information Value Predictive Power &lt;0.02 useless for prediction 0.02 to 0.1 weak predictor 0.1 to 0.3 medium predictor 0.3 to 0.5 strong predictor &gt; 0.5 suspicious or too good to be true <p>It's generally good to have medium and strong predictor.</p> <p>Your woe-binning algorithm typically will target to iteratively choose bin size to get \\(\\sum IV_i\\) to some where between 0.3 - 0.5. </p>"},{"location":"risk_model/woe_iv/#reference","title":"Reference","text":"<p>Some basics</p> <ul> <li>Medium: WoE importance</li> <li>Medium: WoE Binning in real-time credit risk modeling</li> <li>WoE case study</li> </ul> <p>Implementation of the Monotone optimal binning algorithm for credit risk modeling (2017)</p> <ul> <li>GIthub: Monotonic WoE binning algorithm, code implementation</li> <li>Another monotonic WoE binning</li> </ul>"}]}